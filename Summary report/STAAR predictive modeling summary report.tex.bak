\documentclass[journal, a4paper]{IEEEtran}
\usepackage{hyperref} 
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
}
\urlstyle{same}
% some very useful LaTeX packages include:

%\usepackage{cite}      % Written by Donald Arseneau
                        % V1.6 and later of IEEEtran pre-defines the format
                        % of the cite.sty package \cite{} output to follow
                        % that of IEEE. Loading the cite package will
                        % result in citation numbers being automatically
                        % sorted and properly "ranged". i.e.,
                        % [1], [9], [2], [7], [5], [6]
                        % (without using cite.sty)
                        % will become:1
                        % [1], [2], [5]--[7], [9] (using cite.sty)
                        % cite.sty's \cite will automatically add leading
                        % space, if needed. Use cite.sty's noadjust option
                        % (cite.sty V3.8 and later) if you want to turn this
                        % off. cite.sty is already installed on most LaTeX
                        % systems. The latest version can be obtained at:
                        % http://www.ctan.org/tex-archive/macros/latex/contrib/supported/cite/

\usepackage{graphicx}   % Written by David Carlisle and Sebastian Rahtz
                        % Required if you want graphics, photos, etc.
                        % graphicx.sty is already installed on most LaTeX
                        % systems. The latest version and documentation can
                        % be obtained at:
                        % http://www.ctan.org/tex-archive/macros/latex/required/graphics/
                        % Another good source of documentation is "Using
                        % Imported Graphics in LaTeX2e" by Keith Reckdahl
                        % which can be found as esplatex.ps and epslatex.pdf
                        % at: http://www.ctan.org/tex-archive/info/

%\usepackage{psfrag}    % Written by Craig Barratt, Michael C. Grant,
                        % and David Carlisle
                        % This package allows you to substitute LaTeX
                        % commands for text in imported EPS graphic files.
                        % In this way, LaTeX symbols can be placed into
                        % graphics that have been generated by other
                        % applications. You must use latex->dvips->ps2pdf
                        % workflow (not direct pdf output from pdflatex) if
                        % you wish to use this capability because it works
                        % via some PostScript tricks. Alternatively, the
                        % graphics could be processed as separate files via
                        % psfrag and dvips, then converted to PDF for
                        % inclusion in the main file which uses pdflatex.
                        % Docs are in "The PSfrag System" by Michael C. Grant
                        % and David Carlisle. There is also some information
                        % about using psfrag in "Using Imported Graphics in
                        % LaTeX2e" by Keith Reckdahl which documents the
                        % graphicx package (see above). The psfrag package
                        % and documentation can be obtained at:
                        % http://www.ctan.org/tex-archive/macros/latex/contrib/supported/psfrag/

%\usepackage{subfigure} % Written by Steven Douglas Cochran
                        % This package makes it easy to put subfigures
                        % in your figures. i.e., "figure 1a and 1b"
                        % Docs are in "Using Imported Graphics in LaTeX2e"
                        % by Keith Reckdahl which also documents the graphicx
                        % package (see above). subfigure.sty is already
                        % installed on most LaTeX systems. The latest version
                        % and documentation can be obtained at:
                        % http://www.ctan.org/tex-archive/macros/latex/contrib/supported/subfigure/

\usepackage{url}        % Written by Donald Arseneau
                        % Provides better support for handling and breaking
                        % URLs. url.sty is already installed on most LaTeX
                        % systems. The latest version can be obtained at:
                        % http://www.ctan.org/tex-archive/macros/latex/contrib/other/misc/
                        % Read the url.sty source comments for usage information.

%\usepackage{stfloats}  % Written by Sigitas Tolusis
                        % Gives LaTeX2e the ability to do double column
                        % floats at the bottom of the page as well as the top.
                        % (e.g., "\begin{figure*}[!b]" is not normally
                        % possible in LaTeX2e). This is an invasive package
                        % which rewrites many portions of the LaTeX2e output
                        % routines. It may not work with other packages that
                        % modify the LaTeX2e output routine and/or with other
                        % versions of LaTeX. The latest version and
                        % documentation can be obtained at:
                        % http://www.ctan.org/tex-archive/macros/latex/contrib/supported/sttools/
                        % Documentation is contained in the stfloats.sty
                        % comments as well as in the presfull.pdf file.
                        % Do not use the stfloats baselinefloat ability as
                        % IEEE does not allow \baselineskip to stretch.
                        % Authors submitting work to the IEEE should note
                        % that IEEE rarely uses double column equations and
                        % that authors should try to avoid such use.
                        % Do not be tempted to use the cuted.sty or
                        % midfloat.sty package (by the same author) as IEEE
                        % does not format its papers in such ways.

\usepackage{amsmath}    % From the American Mathematical Society
                        % A popular package that provides many helpful commands
                        % for dealing with mathematics. Note that the AMSmath
                        % package sets \interdisplaylinepenalty to 10000 thus
                        % preventing page breaks from occurring within multiline
                        % equations. Use:
%\interdisplaylinepenalty=2500
                        % after loading amsmath to restore such page breaks
                        % as IEEEtran.cls normally does. amsmath.sty is already
                        % installed on most LaTeX systems. The latest version
                        % and documentation can be obtained at:
                        % http://www.ctan.org/tex-archive/macros/latex/required/amslatex/math/



% Other popular packages for formatting tables and equations include:

%\usepackage{array}
% Frank Mittelbach's and David Carlisle's array.sty which improves the
% LaTeX2e array and tabular environments to provide better appearances and
% additional user controls. array.sty is already installed on most systems.
% The latest version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/required/tools/

% V1.6 of IEEEtran contains the IEEEeqnarray family of commands that can
% be used to generate multiline equations as well as matrices, tables, etc.

% Also of notable interest:
% Scott Pakin's eqparbox package for creating (automatically sized) equal
% width boxes. Available:
% http://www.ctan.org/tex-archive/macros/latex/contrib/supported/eqparbox/

% *** Do not adjust lengths that control margins, column widths, etc. ***
% *** Do not use packages that alter fonts (such as pslatex).         ***
% There should be no need to do such things with IEEEtran.cls V1.6 and later.




% Your document starts here!
\begin{document}

% Define document title and author
	\title{Predictive modeling for STAAR test scores}
	\author{An Jiang\\ \bigskip January 2019}
	\date{January 2019}
	\markboth{Imagine Learning}{}
	\maketitle

% Write abstract here
\begin{abstract}	
	We build a machine learning model to predict students' performance in the State of Texas Assessments of Academic Readiness (STAAR) standardized tests. The final prediction is based on students' previous STAAR scores, demographic information, ILL Benchmark test scores and various ILL usage information. We make predictions on students' actual scores as well as classification of At Risk/Not At Risk depending on the below/above the grade level performance assumption.
\end{abstract}

% Each section begins with a \section{title} command
\section{Introduction}
	% \PARstart{}{} creates a tall first letter for this first paragraph
\IEEEPARstart{S}tate of Texas Assessments of Academic Readiness (STAAR) is a series of standardized tests used in the state of Texas. Imagine Learning has collected the STAAR test scores of the 16-17 and 17-18 school years for the students in the Houston school districts as well as their ILL Benchmark test scores, ILL usage information and etc. We build a machine learning regression model to predict the STAAR test scores of the 17-18 school year. We will discuss how we established the regression model and improved its accuracy from two aspects -- data preprocessing and  model selection in the following two sections. Then, we make visualization about the prediction outputs and errors. Next, we transform the regression outputs to the "AtRisk" and "NotAtRisk" indicators according to a below/above the grade level performance assumption. Finally, we analyze the prediction results by grade level, do an interval estimation of the prediction error and discuss the correlation between the internal and external scores. All the datasets and codes are stored in the \href{https://github.com/ImagineLearning/STAAR-score-prediction}{IL GitHub repository} \cite{github}. 
	

% Main Part
\section{Dataset overview}
	State of Texas Assessments of Academic Readiness (STAAR) is a collection of different tests for various subjects and concepts. For the purpose of the assessment for Imagine Language and Literacy, we only care about the test "Reading 3-8" which evaluates the students' ability in English reading. Our model predicts students' STAAR test scores during the 17-18 school year while uses the scores during the 16-17 school year as one of the inputs. The dataset also contains students' demographic information including school name, grade, gender, English language learner (ELL) indicator, ethniciy and attendance rate. It also contains the overall and the item level scores for the three ILL Benchmark tests which were held at the beginning of the year (BOY), the middle of the year (MOY) and the end of the year (EOY) respectively. Each Benchmark test consists of 512 item questions. Usage information contains things like total minutes that a student spent on ILL and whether a student has completed or passed a specific learning activity in ILL. The Benchmark test scores have 2 granularity levels - the overall scaled scores and the item question scores. Similarly, usage time also have 2 granularity levels - the overall total minutes and weekly usage minutes that students spent on ILL respectively. We build 2 models accordingly. Furthermore, we also make comparison between the model with data imputation and the model that is able to handle the missing data automatically. 


\section{Data preprocessing}
\subsection{Load the dataset as dataframes}
	We load the dataset as Pandas dataframes and only keep the student rows with $"Grade" = 3, 4, ..., 8$ since higher grades take different type of reading test other than "Reading 3-8" and lower grades don't take STAAR test at all. In this way, we have 28594 student data samples.   


\subsection{Feature Engineering}
\subsubsection{Missing Data and Imputation}
	Table \ref{tab:MissingData-overall} shows the missing data ratio for the model with the overall scaled Benchmark test scores and the total minutes that a student spent on ILL. 
\begin{table}[!hbt]
		\begin{center}
		\caption{Missing data - overall scaled score and total minutes}
		\label{tab:MissingData-overall}
		\begin{tabular}{c c}
					& Missing Ratio (\%)	\\
			\hline
		Benchmark Vocab EOY Score & 73.823  \\
		Benchmark Literacy EOY Score & 65.045\\
		Benchmark EOY Date &  65.014\\
		Benchmark BOY Date &  61.793\\
		Benchmark Vocab BOY Score & 61.793\\
		Benchmark Literacy BOY Score &   61.793\\
	    Benchmark Vocab MOY Score &   46.429\\
		Benchmark Literacy MOY Score &  40.578\\
		Benchmark MOY Date &   40.418\\
		Reading.Scale.Score 1617 &  36.973 \\
		Reading.Scale.Score 1718 &    6.386\\
		Attendance.Rate 1718 &  0.112 \\
		Ethnicity & 0.045\\
		SPED 1718 &  0.045\\
		ELL 1718 &  0.045\\
		Gender & 0.045
		\end{tabular}
		\end{center}
\end{table}

	We group the student samples by their demographic features and impute the missing values with the mean in each group. This is based on the assumption that students with similar demographic attributes should have similar test performances. We establish 3 level of student attributes for group-by imputation to make it more accurate and complete. 

Table \ref{tab:MissingData-GranularData} shows the missing data ratio for the model with granular data, i.e., item question scores and students' weekly time usage on ILL. 
\begin{table}[!hbt]
		\begin{center}
		\caption{Missing - item scores and weekly time usage}
		\label{tab:MissingData-GranularData}
		\begin{tabular}{c c}
					& Missing Ratio (\%)	\\
			\hline
		Word.Recognition.Form.C.2021.q99 & 100  \\
		Academic.Vocabulary.Easy.Form.C.6021.q249	 & 100\\
		Readables.Comprehension.Form.C.4021.leveled.book.c.3.2 &  100\\
		... & ...\\
		Word.Recognition.2001.q65 & 63.052\\
		Word.Recognition.2001.q62 & 63.052\\
		Benchmark BOY Date &  61.793\\
		Benchmark MOY Date &  40.418\\
		Reading.Scale.Score 1617 & 36.973 \\
		Reading.Scale.Score 1718 &    6.386\\
		Attendance.Rate 1718 &  0.112 \\
		Ethnicity & 0.045\\
		SPED 1718 &  0.045\\
		ELL 1718 &  0.045\\
		Gender & 0.045
		\end{tabular}
		\end{center}
\end{table}


We firstly delete those subtests that have a 100\% missing ratio because they don't provide any information  to the machine learning models. However, for item score models, the overall missing ratio is too high ($>90\%$), which will cause a high bias with imputation. Thus, we decide not to apply imputation on item score models and use models that are able to handle the missing data autonomously like XGBoost and LightGBM algorithms.\\		
	
	
\subsubsection{One-Hot Encoding for Categorical Features}
We use one-hot encoding to handle the categorical features. However, we need to apply the label encoding on some categorical variables that may contain information in their information in their ordering set before one-hot encoding. \\


\subsubsection{Data Normalization for Numerical Features}
Data Normalization is used to standardize the range of independent features of data. Otherwise gradient descent for loss function optimization converges slow or may even diverge. In this model, we use the most widely used data normalization method in machine learning - standardization. The general method of calculation is to determine the distribution mean and the standard deviation for each feature. Next we subtract the mean from each feature. Then we divide the values of each feature by its standard deviation. $$x' = \dfrac{x-\bar{x}}{\sigma}$$ Where $x$ is the original feature vector, $\bar{x}$ is the mean of that feature vector, and $\sigma$ is its standard deviation. Feature standardization makes the values of each feature in the data have zero-mean and unit-variance.



\subsection{Getting the training and test sets}
We split the training and test set randomly with a training-test size ratio equal to 8:2. We apply cross validation on the training set, so there is no explicit validation set. 

\section{Model selection}
Firstly, we define a cross validation strategy as the criterion to compare the performance in accuracy for machine learning models. The strategy is to shuffle the dataset prior to the cross validation with 5 folds, and compute the root mean squared error between the labels and predictions as the measure of loss. 

We compare different types of models using the cross validation strategy mentioned above. Our base models include generalized linear models (Ridge, Lasso, Elastic Net, Kernel Ridge), Random Forest, Extremely Randomized Trees, Gradient boosting, XGBoost and LightGBM. Among these models, XGBoost and LightGBM have the best performance. Then we further boost predictive accuracy by building a stacked model with base models and a meta learner \cite{Stacking}. For the model with feature imputation, we select ENet, Gradient Boosting, KRR and Lasso as base models and Ridge as the meta model. On the other hand, for the models without feature imputations, we select XGBoost and LightGBM as base models and Ridge as the meta model. 

We list the results of the top 3 algorithms for the overall score and usage model as well as the item score and weekly usage model. The overall score and usage model has two sub-cases respectively depending on whether the imputation is applied. Item score and weekly usage model has no imputation and use the algorithms that can handle the missing data autonomously. Here CV stands for cross validation, CV error is the cross validation strategy mentioned above, test error is root mean squared error on the test set. Note that from Table \ref{tab:ErrorOverallImputation} to \ref{tab:ErrorGranularNoImputation}, the error is for the standardized labels.

\begin{table}[!hbt]
		\begin{center}
		\caption{Error - Overall score and usage - Imputation}
		\label{tab:ErrorOverallImputation}
		\begin{tabular}{c | c | c}
		Model & CV error & Test error	\\
		\hline
		XGBoost & 0.6230 &  0.6069 \\
		\hline
		LightGBM & 0.6342 & 0.6203 \\
		\hline
		Stacked model &  0.6188  & 0.6025 \\
		\hline
		\end{tabular}
		\end{center}
	\end{table}

\begin{table}[!hbt]
		\begin{center}
		\caption{Error - Overall score and usage - No imputation}
		\label{tab:ErrorOverallNoImputation}
		\begin{tabular}{c | c | c}
		Model & CV error & Test error	\\
		\hline
		XGBoost & 0.6107  &  0.5925 \\
		\hline
		LightGBM & 0.6213  & 0.6080 \\
		\hline
		Stacked model &  0.6077  & 0.5928 \\
		\hline
		\end{tabular}
		\end{center}
	\end{table}

\begin{table}[!hbt]
		\begin{center}
		\caption{Error - Item score and weekly usage - No imputation}
		\label{tab:ErrorGranularNoImputation}
		\begin{tabular}{c | c | c}
		Model & CV error & Test error	\\
		\hline
		XGBoost & 0.6102 &  0.5937 \\
		\hline
		LightGBM & 0.6232  & 0.6119 \\
		\hline
		Stacked model &  0.6075  & 0.5919 \\
		\hline
		\end{tabular}
		\end{center}
	\end{table}


Observing the tables listed above, we can tell that the stacked model is superior than the other two models no matter what type of scores is used. Moreover, using more granular data is a little bit better than using overall data. The stacked model errors in Table \ref{tab:ErrorGranularNoImputation} is smaller than those in Table \ref{tab:ErrorOverallNoImputation}. Finally, applying the algorithms that can handle the missing values automatically without imputation is a little bit better then data imputation. The stacked model errors in Table \ref{tab:ErrorOverallNoImputation} is smaller than those in Table \ref{tab:ErrorOverallImputation}.



\section{Output visualization}
Firstly, we transform the all the standarized labels back to their original range for all granularity levels of scores and compare the percentage error between the target labels and the predictions of the STAAR test scores in Figure \ref{fig:PEOverallImputation} to Figure \ref{fig:PEItemNoImputation}. 
	\begin{figure}[!hbt]
		\begin{center}
		\includegraphics[width=\columnwidth]{PEOverallImputation}
		\caption{Percentage Error - overall score and usage - Imputation}
		\label{fig:PEOverallImputation}
		\end{center}
	\end{figure}

	\begin{figure}[!hbt]
		\begin{center}
		\includegraphics[width=\columnwidth]{PEOverallNoImputation}
		\caption{Percentage Error - Overall score and usage - No imputation}
		\label{fig:PEOverallNoImputation}
		\end{center}
	\end{figure}

	\begin{figure}[!hbt]
		\begin{center}
		\includegraphics[width=\columnwidth]{PEItemNoImputation}
		\caption{Percentage Error - Item score and weekly usage - No Imputation}
		\label{fig:PEItemNoImputation}
		\end{center}
	\end{figure}

	

We summarize the percentage errors' mean and standard deviation in Table \ref{tab:PEMeanStd}. From this table, we can tell that the item score and usage model without imputation is better than the other two models. On the other hand, imputation helps improve the accuracy in terms of the PE mean a little bit. However, we must realize that imputation is not feasible for item scores because the missing ratio is too high and also it is too difficult to do that. In conclusion, our best model is the stacked model using the item score and weekly usage with no imputation. 
\begin{table}[!hbt]
		\begin{center}
		\caption{Percentage errors' mean and standard deviation}
		\label{tab:PEMeanStd}
		\begin{tabular}{c | c | c}
		 & PE mean (\%) & PE std (\%)		\\
		\hline
		Overall score and usage - Imputation & 4.57  &  4.07 \\
		\hline
		Overall score and usage - No Imputation &  4.49  & 3.99 \\
		\hline
		Item score and weekly usage - No Imputation & 4.51  &  3.96 \\
		\hline
		\end{tabular}
		\end{center}
	\end{table}


\section{The categorization of At Risk/Below Grade Level Performance based on regression outputs}
Table \ref{tab:AtRiskCriterion} is the criterion for "At Risk" and "Not AtRisk" categorization. In the context of STAAR test score prediction, "At Risk" is equivalent to "Below the grade level performance". In other words, a student is considered "at risk" or "below the grade level performance" if her/his STAAR score is less than the criterion number listed in Table \ref{tab:AtRiskCriterion}. 

\begin{table}[!hbt]
		\begin{center}
		\caption{Criterion of At Risk}
		\label{tab:AtRiskCriterion}
		\begin{tabular}{c | c | c}
		Grade & At Risk Max. STAAR Score \\
		\hline
		3 & 1345  \\
		\hline
		4 &  1434 \\
		\hline
		5 & 1470 \\
		\hline
		6 & 1517 \\
		\hline
		7 & 1567 \\
		\hline
		8 & 1587 \\
		\hline
		\end{tabular}
		\end{center}
	\end{table}



Table \ref{tab:ClassificationAccuracy} shows the classification accuracy of the "AtRisk" predictions transformed from the regression outputs.
\begin{table}[!hbt]
		\begin{center}
		\caption{Classification accuracy}
		\label{tab:ClassificationAccuracy}
		\begin{tabular}{c | c | c}
		 & Baseline accuracy & Classification accuracy\\
		\hline
		Overall score and usage - Imputation & 51.16\%  &  79.23\% \\
		\hline
		Overall score and usage - No imputation &  51.16\%  & 79.96\% \\
		\hline
		Item score and weekly usage &  51.16\%  & 79.79\% \\
		\hline
		\end{tabular}
		\end{center}
	\end{table}




\section{Analysis by grade}
In this section, we only consider the model using item score and weekly usage with no imputation which has the best performance among all models.

Figure \ref{fig:EbGItemWeeklyNoImputation} and Figure \ref{fig:AbGItemWeeklyNoImputation} show the root mean squared log error and classification accuracy by grade level respectively.
\begin{figure}[!hbt]
		\begin{center}
		\includegraphics[width=\columnwidth]{EbGItemWeeklyNoImputation}
		\caption{Error by grade level}
		\label{fig:EbGItemWeeklyNoImputation}
		\end{center}
	\end{figure}
	
	\begin{figure}[!hbt]
		\begin{center}
		\includegraphics[width=\columnwidth]{AbGItemWeeklyNoImputation}
		\caption{Classification accuracy by grade level}
		\label{fig:AbGItemWeeklyNoImputation}
		\end{center}
	\end{figure}
	
Figure \ref{fig:MeanbyGradeItemWeekly} shows the comparison between the observed and the predicted mean scores by grade for students' STAAR test. The scores are rounded to integers. By comparison, the predicted mean scores are almost perfectly consistent with the observed mean scores.
	\begin{figure}[!hbt]
		\begin{center}
		\includegraphics[width=\columnwidth]{MeanbyGradeItemWeekly}
		\caption{Mean scores by grade}
		\label{fig:MeanbyGradeItemWeekly}
		\end{center}
	\end{figure}
	
	
 
	
\section{Interval estimate of the prediction error}
	To understand the prediction accuracy intuitively, we discuss the interval estimate of the percentage error mean mentioned in Table \ref{tab:PEMeanStd}. For the item score and weekly usage model with no imputation, the 95\% Confidence interval for the true PE mean of the percentage error is $[4.45\%, 4.67\%]$. The maximum STAAR reading 3-8 test score in the test set is 2017. Multiplying the maximum STAAR score with the upper bound of the corresponding confidence interval, we get an upper bound of the error in score value with a 95\% probability. Thus, our prediction error is at most $2017 \times 4.67\% \approx  94$ for at least 95\% experiments.
	

 


	
% Now we need a bibliography:
\begin{thebibliography}{5}

	%Each item starts with a \bibitem{reference} command and the details thereafter.

	\bibitem{github} %GitHub repo
	IL Universal Sceener project GitHub repository. \url{https://github.com/ImagineLearning/universal-screener}.
	
	\bibitem{Stacking} % Web document
	Ben Gorman. A Kaggler's Guide to Model Stacking in Practice. \url{http://blog.kaggle.com/2016/12/27/a-kagglers-guide-to-model-stacking-in-practice/}.


\end{thebibliography}

% Your document ends here!
\end{document}